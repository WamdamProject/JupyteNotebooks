{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case 1:  What data entered by others can be used to develop a WEAP model for the entire Bear River basin? \n",
    "\n",
    "\n",
    "#### By Adel M. Abdallah, Utah State University, August 2018\n",
    "\n",
    "This notebook demonstrates basic WaMDaM use cases analysis using scientific Python libraries such as [pandas](https://pandas.pydata.org/) and [plotly](https://plot.ly/).  It reads WaMDaM SQLite data from a published HydroShare Generic Resource, runs SQL script, and them uses Python plotly to visualize the results\n",
    "\n",
    "\n",
    "\n",
    "For more info: http://docs.wamdam.org/QuerySelect/use_case_1/\n",
    "\n",
    "  <img src=\"https://github.com/WamdamProject/WaMDaM-software-ecosystem/blob/master/mkdocs/Edit_MD_Files/QuerySelect/images/UseCase1.jpg?raw=true\" style=\"float:right;width:800px;padding:20px\">   \n",
    "Example conceptual mapping showing how the use of controlled vocabulary can help retrieve different available native attributes in datasets for reservoirs in the WEAP model instance.\n",
    "\n",
    "\n",
    "### Steps to reproduce this use case results and plots \n",
    "\n",
    "1. [Import python libraries](#Import) \n",
    "2. [Connect to the WaMDaM populated SQLite file](#Connect) \n",
    "3. [Search for data to expand the WEAP Model from the Lower into the entire Bear River Watershed](#SearchWEAP)\n",
    "4. [Search for data to expand the WASH Model from the Lower into the entire Bear River Watershed](#SearchWASH)\n",
    "5. [Plot the data availability summary Figure](#Plot) \n",
    "6. [Close the SQLite connection](#Close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Import\"></a>\n",
    "# 1. Import python libraries \n",
    "\n",
    "\n",
    "### If you're curious, check out this link here about Installing Python Packages from a Jupyter Notebook\n",
    "\n",
    "https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Import python libraries \n",
    "\n",
    "# set the notebook mode to embed the figures within the cell\n",
    "\n",
    "import plotly\n",
    "plotly.__version__\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "offline.init_notebook_mode(connected=True)\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "init_notebook_mode(connected=True)         # initiate notebook for offline plot\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, SVG, Math, YouTubeVideo\n",
    "import urllib\n",
    "\n",
    "print 'The needed Python libraries have been imported'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Connect\"></a>\n",
    "# 2. Connect to the WaMDaM populated SQLite file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Then we can run queries against it within this notebook :)  \n",
    "\n",
    "# the SQLite file is published here \n",
    "#https://github.com/WamdamProject/WaMDaM_UseCases/blob/master/UseCases_files/3SQLite_database/BearRiverDatasets_June_2018.sqlite\n",
    "\n",
    "conn = sqlite3.connect('BearRiverDatasets_June_2018_Final.sqlite')\n",
    "\n",
    "print 'Connected to the WaMDaM SQLite file called: BearRiverDatasets_June_2018_Final'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"SearchWEAP\"></a>\n",
    "# 3. Search for data to expand the WEAP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. Total required attributes\n",
    "Query_required_URL=\"\"\"\n",
    "https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase1/WEAP/1.1_Identify_WEAPmodel_requirements.sql\n",
    "\"\"\"\n",
    "# Read the query text inside the URL\n",
    "Query_required_text = urllib.urlopen(Query_required_URL).read()\n",
    "# return query result in a pandas data frame\n",
    "result_df_required= pd.read_sql_query(Query_required_text, conn)\n",
    "\n",
    "# uncomment the below line to see the list of attributes\n",
    "# display (result_df_required)\n",
    "\n",
    "\n",
    "# Save the datafrom as a csv file into the Jupyter notebook working space\n",
    "result_df_required.to_csv('UseCases_Results_csv\\WEAP_result_df_required.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "# Count the total number of required attributes needed for WEAP models\n",
    "Count_req_Att=result_df_required.shape[0] #gives number of row count\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2. Total Available attributes\n",
    "Query_Available_URL=\"\"\"\n",
    "https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase1/WEAP/1.2_WHICHAvailableDataForModel_WEAP.sql\n",
    "\"\"\"\n",
    "\n",
    "# Read the query text inside the URL\n",
    "Query_Available_text = urllib.urlopen(Query_Available_URL).read()\n",
    "# return query result in a pandas data frame\n",
    "result_df_Available= pd.read_sql_query(Query_Available_text, conn)\n",
    "\n",
    "# uncomment the below line to see the list of attributes\n",
    "print 'Table x: Summary of available attributes with data to expand the USU 2017 WEAP model to the entire Bear River Basin' \n",
    "display (result_df_Available)\n",
    "\n",
    "\n",
    "# Save the datafrom as a csv file into the Jupyter notebook working space\n",
    "result_df_Available.to_csv('UseCases_Results_csv\\WEAP_result_df_Available.csv', index = False)\n",
    "\n",
    "\n",
    "# Count the total number of Available attributes needed for WEAP models\n",
    "Count_Available_Att=result_df_Available.shape[0] #gives number of row count\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "# 3. Redundant available to choose from\n",
    "Query_Redundant_URL=\"\"\"\n",
    "https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase1/WEAP/1.3_WHEREAvailableDataForModel_WEAP.sql\n",
    "\"\"\"\n",
    "\n",
    "# Read the query text inside the URL\n",
    "Query_Redundant_text = urllib.urlopen(Query_Redundant_URL).read()\n",
    "# return query result in a pandas data frame\n",
    "result_df_Redundant= pd.read_sql_query(Query_Redundant_text, conn)\n",
    "\n",
    "# uncomment the below line to see the list of attributes\n",
    "print 'Table x: Summary of available attributes, nodes and links instances, and sources with data to expand the USU 2017 WEAP model to the entire Bear River Basin' \n",
    "\n",
    "display (result_df_Redundant)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the datafrom as a csv file into the Jupyter notebook working space\n",
    "result_df_Redundant.to_csv('UseCases_Results_csv\\WEAP_result_df_Redundant.csv', index = False)\n",
    "\n",
    "\n",
    "# Count the total number of Redundant attributes needed for WEAP models\n",
    "# Count_Redundant_Att=result_df_Redundant.shape[0] #gives number of row count\n",
    "dfList = result_df_Redundant['SourceAttributeName'].tolist()\n",
    "\n",
    "\n",
    "uniqueVals = np.unique(dfList)\n",
    "\n",
    "Count_Redundant_Att=len(uniqueVals)\n",
    "\n",
    "# Count_Redundant_Att_uniq=\n",
    "\n",
    "# myset = set(Count_Redundant_Att)\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "# 3.1 instances \n",
    "Query_instances_URL=\"\"\"\n",
    "https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase1/WEAP/WHERE_Instances.sql\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Read the query text inside the URL\n",
    "Query_instances_text = urllib.urlopen(Query_instances_URL).read()\n",
    "# return query result in a pandas data frame\n",
    "result_df_Instances= pd.read_sql_query(Query_instances_text, conn)\n",
    "\n",
    "# uncomment the below line to see the list of attributes\n",
    "print 'Table x: Summary of instances to and their sources to expand the USU 2017 WEAP model to the entire Bear River Basin' \n",
    "\n",
    "display (result_df_Instances)\n",
    "\n",
    "\n",
    "\n",
    "# 4. No data available\n",
    "Query_NoData_URL=\"\"\"\n",
    "https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase1/WEAP/1.4_AdditionalDataForModel_WEAP.sql\n",
    "\"\"\"\n",
    "\n",
    "# Read the query text inside the URL\n",
    "Query_NoData_text = urllib.urlopen(Query_NoData_URL).read()\n",
    "# return query result in a pandas data frame\n",
    "result_df_NoData= pd.read_sql_query(Query_NoData_text, conn)\n",
    "\n",
    "# uncomment the below line to see the list of attributes\n",
    "# display (result_df_NoData)\n",
    "\n",
    "\n",
    "# Save the datafrom as a csv file into the Jupyter notebook working space\n",
    "result_df_NoData.to_csv('UseCases_Results_csv\\WEAP_result_df_NoData.csv', index = False)\n",
    "\n",
    "\n",
    "# Count the total number attributes with of NoData as needed for WEAP models\n",
    "Count_NoData_Att=result_df_NoData.shape[0] #gives number of row count\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# prepare the bar chart values to the plot function below\n",
    "Y_values_WEAP=[Count_Available_Att,Count_Redundant_Att]\n",
    "#Y_values_WEAP=[Count_req_Att,Count_Available_Att,Count_Redundant_Att,Count_NoData_Att]\n",
    "Count_req_Att_WEAP=Count_req_Att\n",
    "\n",
    "print Y_values_WEAP,Count_req_Att_WEAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"SearchWASH\"></a>\n",
    "# 4. Search for data to expand the WASH Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Plot\"></a>\n",
    "# 5. Plot the data availability summary Figure (#9)\n",
    "### It shows data vailability summary to the WEAP and WASH models in the upper Bear River Watershed in Utah, Idaho, and Wyoming states\n",
    "\n",
    "\n",
    "![](https://github.com/WamdamProject/WaMDaM-software-ecosystem/blob/master/mkdocs/Edit_MD_Files/QuerySelect/images/UseCase1_fig.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. Total required attributes\n",
    "Query_required_URL=\"\"\"\n",
    "https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase1/WASH/1.5_Identify_WASHmodel_requirements.sql\n",
    "\"\"\"\n",
    "# Read the query text inside the URL\n",
    "Query_required_text = urllib.urlopen(Query_required_URL).read()\n",
    "# return query result in a pandas data frame\n",
    "result_df_required= pd.read_sql_query(Query_required_text, conn)\n",
    "\n",
    "# uncomment the below line to see the list of attributes\n",
    "# display (result_df_required)\n",
    "\n",
    "\n",
    "# Save the datafrom as a csv file into the Jupyter notebook working space\n",
    "result_df_required.to_csv('UseCases_Results_csv\\WASH_result_df_required.csv', index = False)\n",
    "\n",
    "\n",
    "# Count the total number of required attributes needed for WEAP models\n",
    "Count_req_Att=result_df_required.shape[0] #gives number of row count\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2. Total Available attributes\n",
    "Query_Available_URL=\"\"\"\n",
    "https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase1/WASH/1.6_WHICHAvailableDataForModel_WASH.sql\n",
    "\"\"\"\n",
    "\n",
    "# Read the query text inside the URL\n",
    "Query_Available_text = urllib.urlopen(Query_Available_URL).read()\n",
    "# return query result in a pandas data frame\n",
    "result_df_Available= pd.read_sql_query(Query_Available_text, conn)\n",
    "\n",
    "# uncomment the below line to see the list of attributes\n",
    "display (result_df_Available)\n",
    "\n",
    "# Save the datafrom as a csv file into the Jupyter notebook working space\n",
    "result_df_Available.to_csv('UseCases_Results_csv\\WASH_result_df_Available.csv', index = False)\n",
    "\n",
    "\n",
    "# Count the total number of Available attributes needed for WEAP models\n",
    "Count_Available_Att=result_df_Available.shape[0] #gives number of row count\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "# 3. Redundant available to choose from\n",
    "Query_Redundant_URL=\"\"\"\n",
    "https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase1/WASH/1.7_WHEREAvailableDataForModel_WASH.sql\n",
    "\"\"\"\n",
    "\n",
    "# Read the query text inside the URL\n",
    "Query_Redundant_text = urllib.urlopen(Query_Redundant_URL).read()\n",
    "# return query result in a pandas data frame\n",
    "result_df_Redundant= pd.read_sql_query(Query_Redundant_text, conn)\n",
    "\n",
    "# uncomment the below line to see the list of attributes\n",
    "# display (result_df_Redundant)\n",
    "\n",
    "# Save the datafrom as a csv file into the Jupyter notebook working space\n",
    "result_df_Redundant.to_csv('UseCases_Results_csv\\WASH_result_df_Redundant.csv', index = False)\n",
    "\n",
    "# Count the total number of Redundant attributes needed for WEAP models\n",
    "Count_Redundant_Att=result_df_Redundant.shape[0] #gives number of row count\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "# 4. No data available\n",
    "Query_NoData_URL=\"\"\"\n",
    "https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase1/WASH/1.8_AdditionalDataForModel_WASH.sql\n",
    "\"\"\"\n",
    "\n",
    "# Read the query text inside the URL\n",
    "Query_NoData_text = urllib.urlopen(Query_NoData_URL).read()\n",
    "# return query result in a pandas data frame\n",
    "result_df_NoData= pd.read_sql_query(Query_NoData_text, conn)\n",
    "\n",
    "# uncomment the below line to see the list of attributes\n",
    "# display (result_df_NoData)\n",
    "\n",
    "# Save the datafrom as a csv file into the Jupyter notebook working space\n",
    "result_df_NoData.to_csv('UseCases_Results_csv\\WASH_result_df_NoData.csv', index = False)\n",
    "\n",
    "\n",
    "# Count the total number attributes with of NoData as needed for WEAP models\n",
    "Count_NoData_Att=result_df_NoData.shape[0] #gives number of row count\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# prepare the bar chart values to the plot function below\n",
    "Y_values_WASH=[Count_Available_Att,Count_Redundant_Att]\n",
    "# Y_values_WASH=[Count_req_Att,Count_Available_Att,Count_Redundant_Att,Count_NoData_Att]\n",
    "Count_req_Att_WASH=Count_req_Att\n",
    "print Y_values_WASH,Count_req_Att_WASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use Plotly \n",
    "\n",
    "WEAP_bars = go.Bar(\n",
    "    x=['Model attributes with new data ', 'Available in many sources'],\n",
    "    y=Y_values_WEAP,\n",
    "    name='Expand WEAP to entire basin',\n",
    "    marker=dict(\n",
    "        color='#003FFF'),\n",
    ")\n",
    "\n",
    "\n",
    "WASH_bars = go.Bar(\n",
    "    x=['Model attributes with new data ', 'Available in many sources'],\n",
    "    y=Y_values_WASH,\n",
    "    name='Expand WASH to entire basin',\n",
    "    marker=dict(\n",
    "        color='#65BFFF'))\n",
    "\n",
    "data = [WEAP_bars, WASH_bars]\n",
    "\n",
    "print Y_values_WEAP\n",
    "# horizontal line data required \n",
    "WEAPHo = go.Scatter(\n",
    "    x=['Model attributes with new data ', 'Available in many sources'],\n",
    "    y=[Count_req_Att_WEAP, Count_req_Att_WEAP],\n",
    "    mode='lines',\n",
    "        name='WEAP',\n",
    "    hoverinfo='dry',\n",
    "    showlegend=False,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        width='4',\n",
    "        dash = 'dot',\n",
    "        color = '#003FFF'\n",
    "            )\n",
    "                    )\n",
    "data.append(WEAPHo)\n",
    "#\n",
    "# horizontal line data required \n",
    "WASHHo = go.Scatter(\n",
    "    x=['Model attributes with new data ', 'Available in many sources'],\n",
    "    y=[Count_req_Att_WASH, Count_req_Att_WASH],\n",
    "    mode='lines',\n",
    "        name='WASH',\n",
    "    hoverinfo='dry',\n",
    "    showlegend=False,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        width='4',\n",
    "        dash = 'dot',\n",
    "        color = '#65BFFF'\n",
    "            )\n",
    "                    )\n",
    "data.append(WASHHo)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Count_req_Att_WASH\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='group',\n",
    "    \n",
    "    legend=dict(\n",
    "        x=0.25,\n",
    "        y=0.6,orientation=\"v\"),\n",
    "    \n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=-0.15,\n",
    "            y=Count_req_Att_WEAP,\n",
    "            text='Required',\n",
    "            showarrow=False,\n",
    "\n",
    "        ),\n",
    "        dict(\n",
    "            x=-0.15,\n",
    "            y=Count_req_Att_WASH,\n",
    "            text='Required',\n",
    "            showarrow=False,\n",
    "\n",
    "        )\n",
    "    ],\n",
    "    \n",
    "    xaxis=dict(\n",
    "        tickfont=dict(\n",
    "            size=20,\n",
    "           color='#000000',family='arial'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='# of attributes',\n",
    "        titlefont=dict(\n",
    "            size=20,\n",
    "           color='#000000',family='arial'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=20,\n",
    "            color='#000000',family='arial'\n",
    "        )\n",
    "    ),    \n",
    "     autosize=False,\n",
    "    width=860,\n",
    "    height=650,\n",
    "        margin=dict(\n",
    "         b=50,t=50), \n",
    "font=dict(size=20,family='arial',color='#000000'),\n",
    "\n",
    ")\n",
    "\n",
    "fig = {\n",
    "    'data': data,\n",
    "    'layout': layout,}\n",
    "\n",
    "\n",
    "# plotly.offline.iplot(fig,filename = 'UseCase1b.html',image='png')\n",
    "plotly.offline.iplot(fig,filename = 'UseCase1b.html')\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "# Have you encounterd the messages below?\n",
    "# ----------------------------------------------\n",
    "# Javascript error adding output!\n",
    "# ReferenceError: Plotly is not defined\n",
    "# See your browser Javascript console for more details.\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Do the follwoing:\n",
    "\n",
    "# Kernel -> Restart -> Clear all outputs and restart\n",
    "# Save\n",
    "# Close browser\n",
    "# Open browser and run again\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Close\"></a>\n",
    "# 6. Close the SQLite connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn.close()\n",
    "\n",
    "print 'Connection to SQLite engine is disconnected'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![]('https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/8Figures_jpg/UseCase1b.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
