{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaMDaM_Use_Case 3.1_Seasonal: What seasonal flow values to use at a site (e.g., below Steward Dam)? \n",
    "\n",
    "#### By Adel M. Abdallah, Utah State University, August 2018\n",
    "\n",
    "\n",
    "This notebook demonstrates basic WaMDaM use cases analysis using scientific Python libraries such as [pandas](https://pandas.pydata.org/) and [plotly](https://plot.ly/).  It reads WaMDaM SQLite data from a published HydroShare Generic Resource, runs SQL script, and them uses Python plotly to visualize the results\n",
    "\n",
    "This use case identifies five time series and seasonal flow data for the site below Stewart Dam, Idaho\n",
    "\n",
    "\n",
    "Execute the following cells by pressing `Shift-Enter`, or by pressing the play button \n",
    "<img style='display:inline;padding-bottom:15px' src='play-button.png'>\n",
    "on the toolbar above.\n",
    "\n",
    "\n",
    "\n",
    "### Steps to reproduce this use case results and plots \n",
    "\n",
    "1.[Import python libraries](#Import)   \n",
    "   \n",
    "   \n",
    "2.[Connect to the WaMDaM populated SQLite file](#Connect)    \n",
    " \n",
    " \n",
    "3.[Query WaMDaM database for flow seasonal data](#QueryFlowSeasonal)   \n",
    "  \n",
    "  \n",
    "4.[Plot the seasonal figure](#Seasonal_13a)  \n",
    "\n",
    " \n",
    "5.[Query WaMDaM database for time series to create the (cumulative distribution function) CDF plot](#QueryTimeSeries)  \n",
    " \n",
    "6.[Plot the CDF figure ](#PlotCDF)  \n",
    "\n",
    "7.[Close the SQLite and WEAP API connections](#Close)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Import\"></a>\n",
    "# 1. Import python libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import python libraries \n",
    "### set the notebook mode to embed the figures within the cell\n",
    "\n",
    "import plotly\n",
    "plotly.__version__\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "offline.init_notebook_mode(connected=True)\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "init_notebook_mode(connected=True)         # initiate notebook for offline plot\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, SVG, Math, YouTubeVideo\n",
    "import urllib\n",
    "\n",
    "print 'The needed Python libraries have been imported'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Connect\"></a>\n",
    "# 2. Connect to the WaMDaM populated SQLite file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Connect to the WaMDaM populated SQLite file \n",
    "\n",
    "# Then we can run queries against it within this notebook :)  \n",
    "\n",
    "# the SQLite file is published here \n",
    "#https://github.com/WamdamProject/WaMDaM_UseCases/blob/master/UseCases_files/3SQLite_database/BearRiverDatasets_June_2018.sqlite\n",
    "\n",
    "conn = sqlite3.connect('BearRiverDatasets_June_2018_Final.sqlite')\n",
    "\n",
    "print 'Connected to the WaMDaM SQLite file called: BearRiverDatasets_June_2018_Final'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"QueryFlowSeasonal\"></a>\n",
    "# 3. Query WaMDaM dababase for flow seasonal data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 3.1Identify_aggregate_TimeSeriesValues.csv\n",
    "# plot aggregated to monthly and converted to acre-feet time series data of multiple sources\n",
    "\n",
    "\n",
    "\n",
    "# 2.2Identify_aggregate_TimeSeriesValues.csv\n",
    "Query_UseCase3_1_seasonal_URL=\"\"\"\n",
    "https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase3/UseCase3.1/3_Identify_SeasonalValues.sql\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Read the query text inside the URL\n",
    "Query_UseCase3_1_Seasonal_text = urllib.urlopen(Query_UseCase3_1_seasonal_URL).read()\n",
    "\n",
    "\n",
    "# return query result in a pandas data frame\n",
    "result_df_UseCase3_1_Seasonal= pd.read_sql_query(Query_UseCase3_1_Seasonal_text, conn)\n",
    "\n",
    "# uncomment the below line to see the list of attributes\n",
    "display (result_df_UseCase3_1_Seasonal)\n",
    "\n",
    "\n",
    "# Save the datafrom as a csv file into the Jupyter notebook working space\n",
    "result_df_UseCase3_1_Seasonal.to_csv('UseCases_Results_csv\\UseCase3_1_Seasonal.csv', index = False)\n",
    "\n",
    "print \"Queries are done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Seasonal_13a\"></a>\n",
    "# 4. Plot the seasonal figure \n",
    "\n",
    "\n",
    "\n",
    "#### Reproduce this plot [Figure 13-A] in the WaMDaM paper \n",
    "\n",
    "\n",
    "<img src=\"https://github.com/WamdamProject/WaMDaM_UseCases/raw/master/UseCases_files/8Figures_jpg/UseCase3.1_seasonal_a.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 2.3Identify_SeasonalValues\n",
    "\n",
    "# plot Seasonal data for multiple scenarios\n",
    "\n",
    "\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "\n",
    "## read the input data from GitHub csv file which is a direct query output\n",
    "# 3.3Identify_SeasonalValues.csv \n",
    "\n",
    "df_Seasonal =result_df_UseCase3_1_Seasonal\n",
    "#get the many curves by looking under \"ScenarioName\" column header. \n",
    "#Then plot Season name vs season value\n",
    "column_name = \"ScenarioName\"\n",
    "subsets = df_Seasonal.groupby(column_name)\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "#for each subset (curve), set up its legend and line info manually so they can be edited\n",
    "subsets_settings = {\n",
    "    'Bear Wet Year Model': {\n",
    "        'dash': 'solid',\n",
    "         'mode':'lines+markers',\n",
    "        'width':4,\n",
    "        'legend_index': 0,\n",
    "        'legend_name': 'Wet Year Model',\n",
    "         'color':'rgb(41, 10, 216)'\n",
    "        },\n",
    "\n",
    "    'Bear Normal Year Model': { # this oone is the name of subset as it appears in the csv file\n",
    "        'dash': 'solid',     # this is properity of the line (curve)\n",
    "        'width':4,\n",
    "        'mode':'lines+markers',\n",
    "        'legend_index': 1,   # to order the legend\n",
    "        'legend_name': 'Normal Year Model',  # this is the manual curve name \n",
    "         'color':'rgb(38, 77, 255)'\n",
    "\n",
    "        },\n",
    "    'Bear Dry Year Model': {\n",
    "        'dash': 'solid',\n",
    "        'mode':'lines+markers',\n",
    "         'width':4,\n",
    "        'legend_index': 2,\n",
    "        'legend_name': 'Dry Year Model',\n",
    "         'color':'rgb(63, 160, 255)'\n",
    "        },\n",
    "\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "# This dict is used to map legend_name to original subset name\n",
    "subsets_names = {y['legend_name']: x for x,y in subsets_settings.iteritems()}\n",
    "\n",
    "\n",
    "for subset in subsets.groups.keys():\n",
    "    print subset\n",
    "    dt = subsets.get_group(name=subset)\n",
    "    s = go.Scatter(\n",
    "                    x=df_Seasonal.SeasonName,\n",
    "                    y=dt['SeasonNumericValue'],\n",
    "                    name = subsets_settings[subset]['legend_name'],\n",
    "                    line = dict(\n",
    "                        color =subsets_settings[subset]['color'],\n",
    "                        width =subsets_settings[subset]['width'],\n",
    "                        dash=subsets_settings[subset]['dash']\n",
    "                                ),\n",
    "                    marker=dict(size=10),            \n",
    "                    opacity = 0.8\n",
    "                   )\n",
    "    data.append(s)\n",
    "    \n",
    "    \n",
    "# Legend is ordered based on data, so we are sorting the data based \n",
    "# on desired legend order indicarted by the index value entered above\n",
    "data.sort(key=lambda x: subsets_settings[subsets_names[x['name']]]['legend_index'])\n",
    "\n",
    "    \n",
    "\n",
    "layout = dict(\n",
    "    #title = \"Use Case 3.3\",\n",
    "    yaxis = dict(\n",
    "        title = \"Cumulative flow <br> (acre-feet/month)\",\n",
    "        tickformat= ',',\n",
    "        showline=True,\n",
    "        dtick='5000',\n",
    "        ticks='outside',\n",
    "        ticklen=10\n",
    "\n",
    "                ),\n",
    "    \n",
    "    xaxis = dict(\n",
    "        #title = \"Month\",\n",
    "        ticks='inside',\n",
    "\n",
    "        ticklen=25\n",
    "                    ),\n",
    "    legend=dict(\n",
    "        x=0.6,y=0.5,\n",
    "          bordercolor='#00000f',\n",
    "            borderwidth=2\n",
    "               ),\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    #paper_bgcolor='rgb(233,233,233)',\n",
    "    #plot_bgcolor='rgb(233,233,233)',\n",
    "    margin=go.Margin(l=260,b=100),\n",
    "    font=dict(size=35)\n",
    "             )\n",
    "# create a figure object\n",
    "fig = dict(data=data, layout=layout)\n",
    "#py.iplot(fig, filename = \"2.3Identify_SeasonalValues\") \n",
    "\n",
    "\n",
    "## it can be run from the local machine on Pycharm like this like below\n",
    "## It would also work here offline but in a seperate window  \n",
    "offline.iplot(fig,filename = 'UseCase3.1_seasonal_a')#,image='png' )       \n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "# Have you encounterd the messages below? if not, dont worry about it\n",
    "# ----------------------------------------------\n",
    "# Javascript error adding output!\n",
    "# ReferenceError: Plotly is not defined\n",
    "# See your browser Javascript console for more details.\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Do the follwoing:\n",
    "\n",
    "# Kernel -> Restart -> Clear all outputs and restart\n",
    "# Save\n",
    "# Close browser\n",
    "# Open browser and run again\n",
    "print \"the plot is generated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"QueryTimeSeries\"></a>\n",
    "# 5. Query WaMDaM dababase for time series to create the (cumulative distribution function) CDF plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 3.1Identify_aggregate_TimeSeriesValues.csv\n",
    "# plot aggregated to monthly and converted to acre-feet time series data of multiple sources\n",
    "\n",
    "\n",
    "\n",
    "# 2.2Identify_aggregate_TimeSeriesValues.csv\n",
    "Query_UseCase3_1_URL=\"\"\"\n",
    "https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/UseCases_files/4Queries_SQL/UseCase3/UseCase3.1/2_Identify_aggregate_TimeSeriesValues.sql\n",
    "\"\"\"\n",
    "\n",
    "# Read the query text inside the URL\n",
    "Query_UseCase3_1_text = urllib.urlopen(Query_UseCase3_1_URL).read()\n",
    "\n",
    "\n",
    "# return query result in a pandas data frame\n",
    "result_df_UseCase3_1= pd.read_sql_query(Query_UseCase3_1_text, conn)\n",
    "df_TimeSeries=result_df_UseCase3_1\n",
    "# uncomment the below line to see the list of attributes\n",
    "# display (result_df_required)\n",
    "\n",
    "\n",
    "# Save the datafrom as a csv file into the Jupyter notebook working space\n",
    "result_df_UseCase3_1.to_csv('UseCases_Results_csv\\UseCase3_1.csv', index = False)\n",
    "\n",
    "print \"Queries are done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"PlotCDF\"></a>\n",
    "# 6. Plot the CDF figure \n",
    "\n",
    "\n",
    "#### Reproduce this plot [Figure 13-B] in the WaMDaM paper \n",
    "\n",
    "\n",
    "<img src=\"https://github.com/WamdamProject/WaMDaM_UseCases/raw/master/UseCases_files/8Figures_jpg/UseCase3.1_seasonal_b.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the CDF table\n",
    "\n",
    "\n",
    "## read the input data from GitHub csv file which is a direct query output for this  query:\n",
    "# 3.2Identify_aggregate_TimeSeriesValues.sql\n",
    "\n",
    "# Convert CalenderYear column data type to datetime\n",
    "df_TimeSeries['CalenderYear'] = pd.to_datetime(df_TimeSeries['CalenderYear'], errors='coerce')\n",
    "\n",
    "# Slice rows based on DatasetAcronym column\n",
    "subsets = df_TimeSeries.groupby('ResourceTypeAcronym')\n",
    "\n",
    "# Select rows where DatasetAcronym is UDWRFlowData\n",
    "dt = subsets.get_group(name='UDWRFlowData')\n",
    "\n",
    "# From the selected rows, select rows where month is June\n",
    "specific_month = dt.CalenderYear.dt.month == 6\n",
    "\n",
    "# CumulativeMonthly data of the desired DatasetAcronym name and month\n",
    "cumulative_monthly = dt[specific_month].CumulativeMonthly.values.tolist()\n",
    "\n",
    "# Sort cumulative_monthly in ascending order\n",
    "cumulative_monthly.sort()\n",
    "\n",
    "# Save the filtered data to csv, CumulativeMonthly and CalenderYear columns\n",
    "filtered_data = dt[specific_month][['CumulativeMonthly', 'CalenderYear']]\n",
    "filtered_data.to_csv('Filtered Data.csv', index=False)\n",
    "\n",
    "\n",
    "# Create the y-axis list, which should be same length as x-axis and range\n",
    "# from 0 to 1, to represent probability and have equal spacing between it's\n",
    "# numbers, so we create a list of floats starting from 1 to length of\n",
    "# cumsum(which represents the x-axis) + 1, (+1) because we started from 1 not 0,\n",
    "# we want the same length of cumsum, and we are dividing the list by length of\n",
    "# cumsum to produce the desired probability values, So the last number in the\n",
    "# list should be equal to the length of cumsum, so that when we divide both\n",
    "# both values we get 1.\n",
    "# To get the last number equal length of cumsum, we have to use\n",
    "# max range = len(cumsum)+1, because np.arange will stop before\n",
    "# the maximum number, so it will stop at len(cumsum)\n",
    "probability = np.arange(1.0, len(cumulative_monthly)+1) /len(cumulative_monthly) # 1.0 to make it float\n",
    "\n",
    "data = []\n",
    "# just plot the sorted_data array against the number of items smaller \n",
    "# than each element in the array \n",
    "\n",
    "cdf = go.Scatter(\n",
    "    x = cumulative_monthly,\n",
    "    y = probability,\n",
    "        showlegend=True,\n",
    "name='UDWR from 1923 to 2014',\n",
    "    marker = dict(\n",
    "        color='rgb(0, 0, 0)'\n",
    "        )\n",
    "    )\n",
    "\n",
    "cdfdata=pd.DataFrame(data=dict(probability=probability,cumulative_monthly=cumulative_monthly))\n",
    "\n",
    "data.append(cdf)\n",
    "\n",
    "\n",
    "# Save the filtered data to csv, CumulativeMonthly and probability columns\n",
    "filtered_data = cdfdata\n",
    "filtered_data.to_csv('CDF_data.csv', index=False)\n",
    "display (filtered_data)\n",
    "\n",
    "# cdfdata\n",
    "\n",
    "lowerthanDry=cdfdata.loc[cdfdata['cumulative_monthly'] <= 666, 'probability']\n",
    "print 'lowerthanDry='\n",
    "print lowerthanDry\n",
    "\n",
    "UpperthanNormal=cdfdata.loc[cdfdata['cumulative_monthly'] >= 2506, 'probability']\n",
    "print 'UpperthanNormal='\n",
    "print UpperthanNormal\n",
    "\n",
    "UpperthanWet=cdfdata.loc[cdfdata['cumulative_monthly'] >= 17181, 'probability']\n",
    "print 'UpperthanWet='\n",
    "print UpperthanWet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use Case 2.4_plotcdf \n",
    "\n",
    "# plot Cumulative flow for June for the UDWR dataset. \n",
    "# Then get the percentage of time it exceeds dry and wet years \n",
    "\n",
    "# Adel Abdallah\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# vertical line dry year \n",
    "dry = go.Scatter(\n",
    "    x=[666, 666 ],\n",
    "    y=[0, 0.48],\n",
    "    mode='lines',\n",
    "        name='Dry year scenario <br> (BRSDM model)',\n",
    "#     hoverinfo='dry',\n",
    "    showlegend=True,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        width=4,\n",
    "        dash = 'dot',\n",
    "        color = '#3FA0FF'\n",
    "            )\n",
    "                    )\n",
    "data.append(dry)\n",
    "\n",
    "\n",
    "\n",
    "# horizontal line dry year \n",
    "dryHo = go.Scatter(\n",
    "    x=[0, 666 ],\n",
    "    y=[0.48, 0.48],\n",
    "    mode='lines',\n",
    "        name='Dry year scenario <br> (BRSDM model)',\n",
    "#     hoverinfo='dry',\n",
    "    showlegend=False,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        width=4,\n",
    "        dash = 'dot',\n",
    "        color = '#3FA0FF'\n",
    "            )\n",
    "                    )\n",
    "data.append(dryHo)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "# vertical line normal year \n",
    "normal = go.Scatter(\n",
    "    x=[2506, 2506],\n",
    "    y=[0, 0.844],\n",
    "    mode='lines',\n",
    "        name='Normal year scenario <br> (BRSDM model)',\n",
    "#     hoverinfo='wet',\n",
    "    showlegend=True,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        dash = 'dashdot',\n",
    "        width=4,\n",
    "        color = '#264DFF'\n",
    "            )\n",
    "                    )\n",
    "data.append(normal)\n",
    "\n",
    "\n",
    "# horizontal line normal year \n",
    "normalHo = go.Scatter(\n",
    "    x=[0, 2506],\n",
    "    y=[0.844, 0.844],\n",
    "    mode='lines',\n",
    "        name='Normal year scenario <br> (BRSDM model)',\n",
    "#     hoverinfo='wet',\n",
    "    showlegend=False,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        dash = 'dashdot',\n",
    "        width=4,\n",
    "        color = '#264DFF'\n",
    "            )\n",
    "                    )\n",
    "data.append(normalHo)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "# vertical line wet year \n",
    "wet = go.Scatter(\n",
    "    x=[17181, 17181],\n",
    "    y=[0, 0.93],\n",
    "    mode='lines',\n",
    "        name='Wet year scenario <br> (BRSDM model)',\n",
    "#     hoverinfo='wet',\n",
    "    showlegend=True,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        dash = 'dash',\n",
    "        width=4,\n",
    "        color = '#290AD8'\n",
    "            )\n",
    "                    )\n",
    "data.append(wet)\n",
    "\n",
    "\n",
    "# horizontal line wet year \n",
    "wetHo = go.Scatter(\n",
    "    x=[0, 17181],\n",
    "    y=[0.93, 0.93],\n",
    "    mode='lines',\n",
    "        name='Wet year scenario <br> (BRSDM model)',\n",
    "#     hoverinfo='wet',\n",
    "    showlegend=False,\n",
    "    line=dict(\n",
    "        shape='vh',\n",
    "        dash = 'dash',\n",
    "        width=4,\n",
    "        color = '#290AD8'\n",
    "            )\n",
    "                    )\n",
    "data.append(wetHo)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis = dict(\n",
    "        title = \"Cumulative flow for June <br> (acre-feet/month)\",\n",
    "        zeroline=True,\n",
    "         #showline=True,\n",
    "        tickformat= ',',\n",
    "        dtick='10000',\n",
    "        ticks='inside',\n",
    "        ticklen=25,   \n",
    "        range = ['0', '40000'],\n",
    "\n",
    "\n",
    "            ),\n",
    "    yaxis = dict(\n",
    "                title = 'Cumulative probability',\n",
    "                dtick='0.1',\n",
    "                ticks='outside',\n",
    "                ticklen=25,\n",
    "#                 range = ['0', '1'],\n",
    "\n",
    "\n",
    "             showline=True,\n",
    "),\n",
    "    font=dict(size=35,family='arial'),\n",
    "    width=1100,\n",
    "    height=800,\n",
    "    margin=go.Margin(\n",
    "        l=230,\n",
    "        b=150       ),\n",
    "    legend=dict(\n",
    "        x=0.5,y=0.5,\n",
    "            bordercolor='#00000f',\n",
    "            borderwidth=2, \n",
    "     font=dict(\n",
    "            family='arial',\n",
    "            size=35                    )           \n",
    "    ),\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "    )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "offline.iplot(fig,filename = 'UseCase3.1_seasonal_b')#,image='png' )       \n",
    "print \"the plot is generated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Close\"></a>\n",
    "# 6. Close the SQLite connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "\n",
    "print 'Connection to SQLite engine is disconnected'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End :) Congratulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
