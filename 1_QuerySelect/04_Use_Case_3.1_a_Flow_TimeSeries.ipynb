{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaMDaM_Use_Case 3.1: What flow values to use at a site (e.g., below Steward Dam)? \n",
    "\n",
    "#### By Adel M. Abdallah, Utah State University, August 2018\n",
    "\n",
    "This notebook demonstrates basic WaMDaM use cases analysis using scientific Python libraries such as [pandas](https://pandas.pydata.org/) and [plotly](https://plot.ly/).  It reads WaMDaM SQLite data from a published HydroShare Generic Resource, runs SQL script, and them uses Python plotly to visualize the results\n",
    "\n",
    "This use case identifies five time series and seasonal flow data for the site below Stewart Dam, Idaho\n",
    "\n",
    "\n",
    "\n",
    "Execute the following cells by pressing `Shift-Enter`, or by pressing the play button \n",
    "<img style='display:inline;padding-bottom:15px' src='play-button.png'>\n",
    "on the toolbar above.\n",
    "\n",
    "\n",
    "### Steps to reproduce this use case results and plots \n",
    "\n",
    "1.[Import python libraries](#Import)   \n",
    "   \n",
    "   \n",
    "2.[Connect to the WaMDaM populated SQLite file](#Connect)    \n",
    " \n",
    " \n",
    "3.[Query WaMDaM database for flow time series](#QueryFlowTimeSeries)   \n",
    "  \n",
    "  \n",
    "4.[Plot the compiled time series for Stewart Dam (Figure 11-A)](#PlotFlow12A)  \n",
    " \n",
    " \n",
    "5.[Plot the last 15 years to show discrepancy in time series for Stewart Dam (Figure 12-B))](#PlotFlow12B)  \n",
    " \n",
    " \n",
    "6.[Pick a a flow source and update the WaMDaM db to reflect \"Verified\"](#PickaSource)  \n",
    " \n",
    " \n",
    "7.[Close the SQLite and WEAP API connections](#Close)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Import\"></a>\n",
    "# 1. Import python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Import python libraries \n",
    "### set the notebook mode to embed the figures within the cell\n",
    "\n",
    "import plotly\n",
    "plotly.__version__\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "offline.init_notebook_mode(connected=True)\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "init_notebook_mode(connected=True)         # initiate notebook for offline plot\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, SVG, Math, YouTubeVideo\n",
    "import urllib\n",
    "\n",
    "print 'The needed Python libraries have been imported'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Connect\"></a>\n",
    "# 2. Connect to the WaMDaM populated SQLite file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2. Connect to the WaMDaM populated SQLite file \n",
    "\n",
    "\n",
    "# Then we can run queries against it within this notebook :)  \n",
    "\n",
    "# the SQLite file is published here \n",
    "#https://github.com/WamdamProject/WaMDaM_UseCases/blob/master/UseCases_files/3SQLite_database/BearRiverDatasets_June_2018.sqlite\n",
    "\n",
    "WaMDaM_SQLite_Name='BearRiverDatasets_June_2018_Final.sqlite'\n",
    "\n",
    "\n",
    "conn = sqlite3.connect(WaMDaM_SQLite_Name)\n",
    "\n",
    "print 'Connected to the WaMDaM SQLite file called'+': '+ WaMDaM_SQLite_Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"QueryFlowTimeSeries\"></a>\n",
    "# 3. Query WaMDaM database for flow time series \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use Case 3.1Identify_aggregate_TimeSeriesValues.csv\n",
    "# plot aggregated to monthly and converted to acre-feet time series data of multiple sources\n",
    "\n",
    "\n",
    "\n",
    "# 2.2Identify_aggregate_TimeSeriesValues.csv\n",
    "Query_UseCase3_1_URL=\"\"\"\n",
    "https://raw.githubusercontent.com/WamdamProject/WaMDaM_UseCases/master/4_Queries_SQL/UseCase3/UseCase3.1/2_Identify_aggregate_TimeSeriesValues.sql\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Read the query text inside the URL\n",
    "Query_UseCase3_1_text = urllib.urlopen(Query_UseCase3_1_URL).read()\n",
    "\n",
    "\n",
    "# return query result in a pandas data frame\n",
    "result_df_UseCase3_1= pd.read_sql_query(Query_UseCase3_1_text, conn)\n",
    "\n",
    "# uncomment the below line to see the list of attributes\n",
    "# display (result_df_required)\n",
    "\n",
    "\n",
    "# Save the datafrom as a csv file into the Jupyter notebook working space\n",
    "result_df_UseCase3_1.to_csv('UseCases_Results_csv\\UseCase3_1.csv', index = False)\n",
    "\n",
    "print \"Queries are done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"PlotFlow12A\"></a>\n",
    "# 4. Plot the compiled time series for Stewart Dam (Figure xx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. Plot the compiled time series for Stewart Dam (Figure 11-A)\n",
    "\n",
    "\n",
    "df_TimeSeries=result_df_UseCase3_1\n",
    "# identify the data for four time series only based on the DatasetAcronym column header \n",
    "column_name = \"ResourceTypeAcronym\"\n",
    "subsets = df_TimeSeries.groupby(column_name)\n",
    "data = []\n",
    "\n",
    "# for each subset (curve), set up its legend and line info manually so they can be edited\n",
    "subsets_settings = {\n",
    "    'UDWRFlowData': {\n",
    "        'dash': 'solid',\n",
    "        'legend_index': 0,\n",
    "        'legend_name': 'Utah Division of Water Res.',\n",
    "        'width':3,\n",
    "        'color':'rgb(153, 15, 15)'\n",
    "        },\n",
    "    'CUAHSI': {\n",
    "        'dash': 'dash',\n",
    "        'legend_index': 1,\n",
    "        'legend_name': 'USGS',\n",
    "        'width':4,\n",
    "        'color':'rgb(15, 107, 153)'\n",
    "        },\n",
    "    'IdahoWRA': {\n",
    "        'dash': 'solid',\n",
    "        'legend_index': 2,\n",
    "        'legend_name': 'Idaho Department of Water Res.',\n",
    "        'width':3,\n",
    "        'color':'rgb(38, 15, 153)'\n",
    "        },    \n",
    "    'BearRiverCommission': { # this oone is the name of subset as it appears in the csv file\n",
    "        'dash': 'dot',     # this is properity of the line (curve)\n",
    "        'legend_index': 3,   # to order the legend\n",
    "        'legend_name': 'Bear River Commission',  # this is the manual curve name \n",
    "         'width':4,\n",
    "        'color':'rgb(107, 153, 15)'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "# This dict is used to map legend_name to original subset name\n",
    "subsets_names = {y['legend_name']: x for x,y in subsets_settings.iteritems()}\n",
    "\n",
    "# prepare the scater plot for each curve\n",
    "for subset in subsets.groups.keys():\n",
    "    #print subset\n",
    "    dt = subsets.get_group(name=subset)\n",
    "    s = go.Scatter(\n",
    "                    x=dt.CalenderYear.map(lambda z: str(z)[:-3]),\n",
    "                    y=dt['CumulativeMonthly'],\n",
    "                    name = subsets_settings[subset]['legend_name'],\n",
    "                    line = dict(\n",
    "                        color =subsets_settings[subset]['color'],\n",
    "                        width =subsets_settings[subset]['width'], \n",
    "                        dash=subsets_settings[subset]['dash']\n",
    "                               ),\n",
    "                        opacity = 1                                \n",
    "                  )\n",
    "    data.append(s)\n",
    "    \n",
    "# Legend is ordered based on data, so we are sorting the data based \n",
    "# on desired legend order indicarted by the index value entered above\n",
    "data.sort(key=lambda x: subsets_settings[subsets_names[x['name']]]['legend_index'])\n",
    "\n",
    "# set up the figure layout parameters\n",
    "layout = dict(\n",
    "     #title = \"UseCase3.2\",\n",
    "     yaxis = dict(\n",
    "         title = \"Cumulative monthly flow <br> (acre-feet/month)\",\n",
    "         tickformat= ',',\n",
    "         zeroline=True,\n",
    "         showline=True,\n",
    "         ticks='outside',\n",
    "         ticklen=15,\n",
    "         #zerolinewidth=4,\n",
    "         zerolinecolor='#00000f',\n",
    "\n",
    "         dtick=30000,\n",
    "                 ),\n",
    "    xaxis = dict(\n",
    "         #title = \"Time <br> (month/year)\",\n",
    "         #autotick=False,\n",
    "        tick0='1900-01-01',\n",
    "        dtick='M180',\n",
    "        ticks='inside',\n",
    "        tickwidth=0.5,\n",
    "        #zerolinewidth=4,\n",
    "        ticklen=27,\n",
    "        zerolinecolor='#00000f',\n",
    "        tickcolor='#000',\n",
    "        tickformat= \"%Y\",\n",
    "       range = ['1920', '2020']\n",
    "\n",
    "                ),\n",
    "    legend=dict(\n",
    "        x=0.2,y=0.9,\n",
    "        bordercolor='#00000f',\n",
    "            borderwidth=2\n",
    "\n",
    "\n",
    "                ),\n",
    "    autosize=False,\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    margin=go.Margin(l=300, b=150),\n",
    "    #paper_bgcolor='rgb(233,233,233)',\n",
    "    #plot_bgcolor='rgb(233,233,233)',\n",
    "    \n",
    "    \n",
    "    font=dict( size=35)\n",
    "             )\n",
    "# create the figure object            \n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "# plot the figure \n",
    "offline.iplot(fig,filename = 'UseCase3.1a_TimeSeries')#,image='png' )       \n",
    "\n",
    "\n",
    "## it can be run from the local machine on Pycharm like this like below\n",
    "## It would also work here offline but in a seperate window  \n",
    "\n",
    "#plotly.offline.plot(fig, filename = \"2.2Identify_aggregate_TimeSeriesValues.html\") \n",
    "\n",
    "###########################################################################################################\n",
    "# Have you encounterd the messages below? if not, dont worry about it\n",
    "# ----------------------------------------------\n",
    "# Javascript error adding output!\n",
    "# ReferenceError: Plotly is not defined\n",
    "# See your browser Javascript console for more details.\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Do the follwoing:\n",
    "\n",
    "# Kernel -> Restart -> Clear all outputs and restart\n",
    "# Save\n",
    "# Close browser\n",
    "# Open browser and run again\n",
    "\n",
    "print \"the plot is generated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"PlotFlow12B\"></a>\n",
    "# 5. Plot the last 15 years to show discrepency in time series for Stewart Dam (Figure xx-B)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. Plot the last 15 years to show discrepency in time series for Stewart Dam (Figure 12-b)\n",
    "\n",
    "# Use Case 2.2bIdentify_aggregate_TimeSeriesValues.py\n",
    "# plot aggregated to monthly and converted to acre-feet time series data of multiple sources\n",
    "\n",
    "# Adel Abdallah\n",
    "# November 16, 2017\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "\n",
    "## read the input data from GitHub csv file which is a direct query output for this  query:\n",
    "# 3.2Identify_aggregate_TimeSeriesValues.sql\n",
    "\n",
    "\n",
    "# identify the data for four time series only based on the DatasetAcronym column header \n",
    "column_name = \"ResourceTypeAcronym\"\n",
    "subsets = df_TimeSeries.groupby(column_name)\n",
    "data = []\n",
    "\n",
    "# for each subset (curve), set up its legend and line info manually so they can be edited\n",
    "\n",
    "subsets_settings = {\n",
    "    'UDWRFlowData': {\n",
    "        'symbol': \"star\",\n",
    "        'legend_index': 0,\n",
    "        'legend_name': 'Utah Division of Water Res.',\n",
    "        'width':2,\n",
    "        'size' :7,\n",
    "        'color':'rgb(153, 15, 15)',\n",
    "        'mode': 'lines+markers'\n",
    "        },\n",
    "    'CUAHSI': {\n",
    "        'symbol': \"square\",\n",
    "        'legend_index': 1,\n",
    "         'size' :10,\n",
    "        'legend_name': 'CUAHSI',\n",
    "        'width':3,\n",
    "        'color':'rgb(15, 107, 153)',\n",
    "        'show_legend': False,\n",
    "        },\n",
    "    'IdahoWRA': {\n",
    "        'symbol': \"triangle-down\",\n",
    "        'legend_index': 2,\n",
    "         'size' :6,\n",
    "        'legend_name': 'Idaho Department of Water Res.',\n",
    "        'width':3,\n",
    "        'color':'rgb(38, 15, 153)'\n",
    "        },    \n",
    "    'BearRiverCommission': { # this one is the name of subset as it appears in the csv file\n",
    "        'symbol': 106,     # this is property of the line (curve)\n",
    "                'size' :6,\n",
    "\n",
    "        'legend_index': 3,   # to order the legend\n",
    "        'legend_name': \"Bear River Commission\",  # this is the manual curve name \n",
    "         'width':4,\n",
    "        'color':'rgb(107, 153, 15)'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "# This dict is used to map legend_name to original subset name\n",
    "subsets_names = {y['legend_name']: x for x,y in subsets_settings.iteritems()}\n",
    "\n",
    "# prepare the scater plot for each curve\n",
    "for subset in subsets.groups.keys():\n",
    "    print subset\n",
    "    dt = subsets.get_group(name=subset)\n",
    "    s = go.Scatter(\n",
    "        x=dt.CalenderYear.map(lambda z: str(z)[:-3]),\n",
    "        y=dt['CumulativeMonthly'],\n",
    "        name = subsets_settings[subset]['legend_name'],       \n",
    "        opacity = 1,\n",
    "        \n",
    "        # Get mode from settings dictionary, if there is no mode\n",
    "        # defined in dictinoary, then default is markers.\n",
    "        mode = subsets_settings[subset].get('mode', 'markers'),\n",
    "        \n",
    "        # Get legend mode from settings dictionary, if there is no mode\n",
    "        # defined in dictinoary, then default is to show item in legend.\n",
    "        showlegend = subsets_settings[subset].get('show_legend', True),\n",
    "        \n",
    "        marker = dict(\n",
    "            size =subsets_settings[subset]['size'],\n",
    "            color = '#FFFFFF',      # white\n",
    "            symbol =subsets_settings[subset]['symbol'],\n",
    "            line = dict(\n",
    "                color =subsets_settings[subset]['color'],\n",
    "                width =subsets_settings[subset]['width'], \n",
    "                ),\n",
    "            ),\n",
    "            \n",
    "        line = dict(\n",
    "            color =subsets_settings[subset]['color'],\n",
    "            width =subsets_settings[subset]['width'], \n",
    "            ),\n",
    "        )\n",
    "    \n",
    "    data.append(s)\n",
    "    \n",
    "# Legend is ordered based on data, so we are sorting the data based \n",
    "# on desired legend order indicated by the index value entered above\n",
    "data.sort(key=lambda x: subsets_settings[subsets_names[x['name']]]['legend_index'])\n",
    "\n",
    "# set up the figure layout parameters\n",
    "layout = dict(\n",
    "     #title = \"UseCase3.2\",\n",
    "     yaxis = dict(\n",
    "         title = \"Cumulative monthly flow <br> (acre-feet/month)\",\n",
    "         tickformat= ',',\n",
    "         zeroline=True,\n",
    "         showline=True,\n",
    "         ticks='outside',\n",
    "         ticklen=15,\n",
    "         #zerolinewidth=4,\n",
    "         zerolinecolor='#00000f',\n",
    "         range = ['0', '6000'],\n",
    "         dtick=1000,\n",
    "                 ),\n",
    "    xaxis = dict(\n",
    "         #title = \"Time <br> (month/year)\",\n",
    "         #autotick=False,\n",
    "        tick0='1994-01-01',\n",
    "        showline=True,\n",
    "        dtick='M12',\n",
    "        ticks='outside',\n",
    "        tickwidth=0.5,\n",
    "        #zerolinewidth=4,\n",
    "        ticklen=27,\n",
    "        #zerolinecolor='#00000',\n",
    "        tickcolor='#000',\n",
    "        tickformat= \"%Y\",\n",
    "        range = ['1994', '2000']\n",
    "                ),\n",
    "    legend=dict(\n",
    "        x=0.3,y=1,\n",
    "        bordercolor='#00000f',\n",
    "            borderwidth=2\n",
    "\n",
    "\n",
    "                ),\n",
    "    autosize=False,\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    margin=go.Margin(l=300, b=150),\n",
    "    #paper_bgcolor='rgb(233,233,233)',\n",
    "    #plot_bgcolor='rgb(233,233,233)',\n",
    "    \n",
    "    \n",
    "    font=dict( size=35)\n",
    "             )\n",
    "             \n",
    "# create the figure object            \n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "# plot the figure \n",
    "#py.iplot(fig, filename = \"2.2bIdentify_aggregate_TimeSeriesValues\")       \n",
    "\n",
    "\n",
    "## it can be run from the local machine on Pycharm like this like below\n",
    "## It would also work here offline but in a seperate window  \n",
    "offline.iplot(fig,filename = 'UseCase3.1b_TimeSeries')#,image='png' )       \n",
    "print \"the plot is generated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"PickaSource\"></a>\n",
    "# 6. Pick a a flow source and update the db to reflect \"Verified\"\n",
    "\n",
    "This \"Update\" SQL query allows users to update the Mappings table to indicate a \"verified\" DataValue. \n",
    "A verified record set to True indicates that the user has verified, curated, checked, or selected this \n",
    "data value as ready to be used for models. A verified record can then be used from an automated script to \n",
    "serve data to models. Its particularly useful when the same set of controlled object type, attribute, and instances names \n",
    "return multiple data values from different sources with potentially similar or different values due to many factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6. Pick a a flow source and update the db to reflect \"Verified\"\n",
    "\n",
    "# scenario_name_data = subsets.get_group(name='Base case')\n",
    "# print scenario_name_data\n",
    "# Get a cursor object\n",
    "\n",
    "SQL_update = \"\"\"\n",
    "UPDATE Mappings \n",
    "\n",
    "SET Verified= 'True'\n",
    "WHERE  MappingID in\n",
    "\n",
    "(SELECT Mappings.MappingID FROM Mappings\n",
    "\n",
    "-- Join the Mappings to get their Attributes\n",
    "LEFT JOIN \"Attributes\"\n",
    "ON Attributes.AttributeID= Mappings.AttributeID\n",
    "\n",
    "-- Join the Attributes to get their ObjectTypes\n",
    "LEFT JOIN  \"ObjectTypes\"\n",
    "ON \"ObjectTypes\".\"ObjectTypeID\"=\"Attributes\".\"ObjectTypeID\"\n",
    "\n",
    "-- Join the Mappings to get their Instances   \n",
    "LEFT JOIN \"Instances\" \n",
    "ON \"Instances\".\"InstanceID\"=\"Mappings\".\"InstanceID\"\n",
    "\n",
    "-- Join the Mappings to get their ScenarioMappings   \n",
    "LEFT JOIN \"ScenarioMappings\"\n",
    "ON \"ScenarioMappings\".\"MappingID\"=\"Mappings\".\"MappingID\"\n",
    "\n",
    "-- Join the ScenarioMappings to get their Scenarios   \n",
    "LEFT JOIN \"Scenarios\"\n",
    "ON \"Scenarios\".\"ScenarioID\"=\"ScenarioMappings\".\"ScenarioID\"\n",
    "\n",
    "-- Join the Scenarios to get their MasterNetworks   \n",
    "LEFT JOIN \"MasterNetworks\" \n",
    "ON \"MasterNetworks\".\"MasterNetworkID\"=\"Scenarios\".\"MasterNetworkID\"\n",
    "\n",
    "where \n",
    "ObjectTypes.ObjectType='Site'  \n",
    "\n",
    "AND \"Instances\".\"InstanceName\"=\"10046500.MONBEAR RIVER BL STEWART DAM NR MONTPELIER IDAHO\"  \n",
    "\n",
    "AND AttributeName='Delivered volume per month'\n",
    "\n",
    "AND ScenarioName='Existing data'\n",
    "\n",
    "AND MasterNetworkName='UDWRFlowData')\n",
    "\"\"\"\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "res = cur.execute(SQL_update)\n",
    "\n",
    "print 'updated'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Close\"></a>\n",
    "# 7. Close the SQLite connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()\n",
    "\n",
    "print 'Connection to SQLite engine is disconnected'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End :) Congratulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
